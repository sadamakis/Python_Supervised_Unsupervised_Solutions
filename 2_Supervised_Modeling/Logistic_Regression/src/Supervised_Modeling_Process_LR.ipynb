{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811a4d67-7a58-4876-809d-0d458d5af588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the notebook full screen\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e4a306-c188-4322-b9dc-a1945462d1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import sys \n",
    "\n",
    "if sys.version_info[:3] < (3,4):\n",
    "    os.getcdw()\n",
    "    code_dir = os.path.dirname(os.getcdw())\n",
    "    project_dir = os.path.dirname(os.path.dirname(os.getcdw()))\n",
    "    data_path = os.path.join(code_dir, \"data\")\n",
    "    functions_path = os.path.join(project_dir, \"functions\")\n",
    "else: \n",
    "    from pathlib import Path\n",
    "    current_directory = os.path.dirname(Path.cwd())\n",
    "    code_dir = os.path.dirname(os.path.dirname(current_directory))\n",
    "    project_dir = os.path.join(code_dir, \"2_Supervised_Modeling\\\\Logistic_Regression\")\n",
    "    data_path = os.path.join(code_dir, \"2_Supervised_Modeling\\\\Logistic_Regression\\\\data\")\n",
    "    functions_path = os.path.join(code_dir, 'functions')\n",
    "    \n",
    "print(code_dir)\n",
    "print(project_dir)\n",
    "print(data_path)\n",
    "print(functions_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481f4f52-0696-4ae1-bc95-872a27ff04d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Python modules\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c4c50-c0a9-4bb8-bbdd-3a3577db63e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path for the library\n",
    "import sys\n",
    "sys.path.insert(0, functions_path)\n",
    "import data_transformation as dtran\n",
    "import variable_reduction as vr\n",
    "import feature_elimination as fe\n",
    "import machine_learning as ml\n",
    "import reports as rp\n",
    "import useful_functions as ufun\n",
    "from load_data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba69179b-c611-4e48-81b9-288704db5818",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eb9ff6-092c-4045-b77b-cbfdd806f4a9",
   "metadata": {},
   "source": [
    "# Initialize the solution variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79160fd2-bbd1-4867-8e81-a5ce75059076",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(project_dir, 'data/input/Supervised_Modeling_Solution_Input.json')) as f:\n",
    "    inputs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97136bd-4dae-4125-8fec-d25b1520dcb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba251a6-b67b-420e-a894-857de08b1b4b",
   "metadata": {},
   "source": [
    "## Essential parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b5b784-ed72-4cb5-8665-88243a6cb2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# String. Specify how to load the data. Options: csv, parq.\n",
    "Load_from = inputs[\"Load_from\"]\n",
    "# String. Specify the data location: this is the folder where the data for this project are saved. \n",
    "data_location = inputs[\"data_location\"]\n",
    "# String. Set the input data file. \n",
    "table_name = inputs[\"table_name\"]\n",
    "# Float. Number between 0-1 determining what percent of data to subsample. \n",
    "sample = float(inputs[\"sample\"])\n",
    "# String. Set the target variable name in the original dataset. \n",
    "target_variable_name = inputs[\"target_variable_name\"]\n",
    "# String. Set the weight variable name in the original dataset. If not avaulable, then provide \"None\" with quotes.\n",
    "weight_variable_name = inputs[\"weight_variable_name\"]\n",
    "# String. Set the sample column that has sample information, e.g. train/test/OOT or segment information, and will be used to split the data in different samples\n",
    "# If this column does not exist, then provide \"None\" with quotes.\n",
    "sample_variable_name = inputs[\"sample_variable_name\"]\n",
    "# String. Set the monetary loss associated with a delinquent case, if available. If this information does not exist, then provide \"None\" with quotes.\n",
    "amount_variable_name = inputs[\"amount_variable_name\"]\n",
    "# List of strings. Set the sub-sample values that are in the sample_variable_name field, e.f. for train/test data split and/or for different segments. \n",
    "# All samples defined in this parameters will be picked up by the solution and results will be created for these samples. \n",
    "# The first sample in the list will be used to train models. \n",
    "# If sample column does not exist, then provide '[None]' (without quotes).\n",
    "sample_values = inputs[\"sample_values\"]\n",
    "# List. Provide the feature names for the numeric variables that will be used for modeling. \n",
    "original_candidate_variables_numeric = inputs[\"numeric_variables_modeling\"]\n",
    "# List. Provide the feature names for the character variables that will be used for modeling. \n",
    "original_candidate_variables_character = inputs[\"character_variables_modeling\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba96f056-7353-42c3-bb1f-1be4c34714a0",
   "metadata": {},
   "source": [
    "## Advanced parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4a8d27-1b3f-438e-8485-69d867daf5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Float. Takes values between 0 and 1. Used in 'select_missing_variables_to_drop' function. Variables with percentage missing values above this threshold will be \n",
    "# dropped from the rest of the process. \n",
    "select_missing_variables_to_drop_threshold = inputs[\"select_missing_variables_to_drop_threshold\"]\n",
    "# Integer. Used in 'character_classification' function. Character variables with more levels than this threshold will be dropped from the rest of the process. \n",
    "character_classification_threshold = inputs[\"character_classification_threshold\"]\n",
    "# Float. Used in the 'replace_outliers' function in the outlier removal section. This is the coefficient for Interquantile range. \n",
    "# It can be used to adjust how many outliers to replace; the higher the value the less outliers are replaced. \n",
    "iqr_coef = inputs[\"iqr_coef\"]\n",
    "# String. Used in 'impute_missing' class. Select the stratefy to impute the missing values. Current options are \"median\", \"mean\", \n",
    "# or a specific value without quotes, e.g. 0.\n",
    "impute_missing_imputation_strategy = inputs[\"impute_missing_imputation_strategy\"]\n",
    "# Float. Variables with Gini coefficient below this threshold will be dropped from the reamained of the analysis. \n",
    "gini_threshold = inputs[\"gini_threshold\"]\n",
    "# Float. Used in 'corr_eliminator' function in the initial correlations calculations. Variables with correlation greater than this threshold will be dropped. \n",
    "corr_threshold = inputs[\"corr_threshold\"]\n",
    "# Int. Used in the 'corr_eliminator' function in the initial correlations calculations. After highly correlated features are dropped, this is the number of the next highest correlations. \n",
    "top_n = eval(inputs[\"top_n\"])\n",
    "# Float. Used in the 'vif_eliminator' function in the initial VIF calculations. Variables with VIF greater than this threshold will be dropped.\n",
    "# This paramater is only applicable if VIF_reduction=true. \n",
    "first_vif_threshold = inputs[\"first_vif_threshold\"]\n",
    "# Float. Used in the 'vif_eliminator' function in the Lasso Logistic Regression. Variables with VIF greater than this threshold will be dropped.\n",
    "second_vif_threshold = inputs[\"second_vif_threshold\"]\n",
    "# String. User selects which criterion to optimize for feature selection. Options are: \"AIC\", \"BIC\".\n",
    "lasso_criterion = inputs[\"lasso_criterion\"]\n",
    "# Boolean. Used to determine whether VIF is run after the correlation feature elimination step. \n",
    "VIF_reduction = inputs[\"VIF_reduction\"]\n",
    "# String. This is the solver argument in sklearn.LogisticRegression. Use 'saga' to reproduce the results, but there might be convergence warnings. \n",
    "# Use 'liblinear' to avoid convergence warnings, but the results will not be reproducible. \n",
    "LogisticRegression_solver = inputs[\"LogisticRegression_solver\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e438bde-3333-478d-93e1-5df10740b2b8",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24b4d66-7b86-4f49-a97a-9dfcd556b0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = load_data(method = Load_from, \n",
    "                     data_path = data_location, \n",
    "                     table_name = table_name, \n",
    "                     sample = sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a47f3de-ccf2-45ee-8453-5d06735fc594",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3680f4f7-c64b-429c-bb80-12a0c862b584",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99195db0-d86a-466c-a18e-0ee19ee64de7",
   "metadata": {},
   "source": [
    "# Replace column name characters that are not compatible with the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5e287e-ebed-41b2-974a-cd85b516f48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full.columns = data_full.columns.str.replace(\",\", \"/\")\n",
    "original_candidate_variables_numeric = [item.replace(\",\", \"/\") for item in original_candidate_variables_numeric]\n",
    "original_candidate_variables_character = [item.replace(\",\", \"/\") for item in original_candidate_variables_character]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929d4911-7cc7-428f-8d88-45aaa2ed195f",
   "metadata": {},
   "source": [
    "# Create the Weight, Sample and Amount variables, if not available in the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc28f36-a586-441c-b918-7e5462b0b0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the weight variable, if it doesn't exist.\n",
    "data_full, weight_variable_name_solution = dtran.weight_var_assignment(input_data = data_full, \n",
    "                                                                                     weight_variable = weight_variable_name)\n",
    "\n",
    "# Create the sample variable, if it doesn't exist.\n",
    "data_full, sample_values_solution, sample_variable_name_solution = dtran.sample_var_assignment(input_data = data_full, \n",
    "                                                                                        sample_variable = sample_variable_name,\n",
    "                                                                                        sample_values = sample_values)\n",
    "\n",
    "# Create the amount variable, if it doesn't exist.\n",
    "data_full, amount_variable_name_solution = dtran.amount_var_assignment(input_data = data_full, \n",
    "                                                                                     amount_variable = amount_variable_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eae0a38-8fb8-4686-8e03-afbc14583a6c",
   "metadata": {},
   "source": [
    "# Subset the dataset to use only the samples selected by 'sample values'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eddf99-6f82-4bba-a954-d54bbba429df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = data_full[data_full[sample_variable_name_solution].isin(sample_values_solution)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05fa0d3-f687-4ff8-81b1-4bdcd384cb5f",
   "metadata": {},
   "source": [
    "# Convert variable data types based on user information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dcd5f3-c4f9-4af2-97ef-34a9ff582c6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert character variables\n",
    "data_full, character_variables_list = dtran.convert_character_var(input_data = data_full, \n",
    "                                                        character_variables = original_candidate_variables_character,\n",
    "                                                        sample_variable = sample_variable_name_solution)\n",
    "\n",
    "# Convert numeric variables\n",
    "data_full, numeric_variables_list = dtran.convert_numeric_var(input_data = data_full, \n",
    "                                                        numeric_variables = original_candidate_variables_numeric,\n",
    "                                                        weight_variable = weight_variable_name_solution, \n",
    "                                                        amount_variable = amount_variable_name_solution, \n",
    "                                                        target_variable = target_variable_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec215d6e-1a0a-4cbb-9b28-85ba476a96f6",
   "metadata": {},
   "source": [
    "# Data quality report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9d6eff-1d3b-4e9d-b5e8-2199873a0dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder, if it doesn't exist\n",
    "ufun.create_folder(data_path = data_path, \n",
    "                   folder_name = 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baae1e7-be72-4f91-a5f7-384f88378124",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dq = rp.dq_report(input_data = data_full, \n",
    "                data_path = data_path, \n",
    "                variables = character_variables_list + numeric_variables_list, \n",
    "                weight_variable = weight_variable_name_solution, \n",
    "                dq_report_file = 'data_quality_report.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c670fb-a527-4ca5-aca8-59694138182f",
   "metadata": {},
   "source": [
    "# Split sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15870ef1-fbea-4446-af80-8aa295e65658",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sample_values_dict = dtran.split_sample_data(\n",
    "    input_data=data_full, \n",
    "    sample_values_solution=sample_values_solution, \n",
    "    sample_variable_name_solution=sample_variable_name_solution\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0229ddf9-035c-4e08-93aa-9c4fd57ce689",
   "metadata": {},
   "source": [
    "# Set the original candidate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecc5066-89ef-4e75-8dd0-dc0eab583f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_candidate_variables = original_candidate_variables_character + original_candidate_variables_numeric\n",
    "print(ufun.color.BLUE + 'Original candidate variables: ' + ufun.color.END + str(original_candidate_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f35b0e-1824-4b26-a14b-34473e054d44",
   "metadata": {},
   "source": [
    "# Remove variables with high missing values percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e79733-2d94-49d9-bc96-ec499df6bdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables excluded from the non-predictive features: keys, target, sample, etc\n",
    "excluded_variables = [x for x in data['data_{}'.format(sample_values_solution[0])].columns if x not in original_candidate_variables]\n",
    "print(ufun.color.BLUE + 'Variables to be excluded: ' + ufun.color.END + str(excluded_variables))\n",
    "print()\n",
    "# Produce and save the missing values table to review\n",
    "missing_variables_table, missing_variables = vr.missing_values_vars(\n",
    "    sample_values_dict=sample_values_dict, \n",
    "    data_path=data_path, \n",
    "    input_data=data, \n",
    "    weight_variable_name_solution=weight_variable_name_solution, \n",
    "    select_missing_variables_to_drop_threshold=select_missing_variables_to_drop_threshold\n",
    "    )\n",
    "# Create the variables to remove: non-predictors + variables with too many missing information\n",
    "excluded_variables = excluded_variables + missing_variables\n",
    "print(ufun.color.BLUE + 'Variables to remove from the remainder of the analysis: ' + ufun.color.END + str(excluded_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0c0e14-df5c-4af2-b574-e65b13c658b5",
   "metadata": {},
   "source": [
    "# Remove character variables with many levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64546dd3-f228-401b-976c-ac6cd142e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_char_vars_levels, excl_char_vars = vr.character_var_levels(\n",
    "    input_data = data, \n",
    "    data_path = data_path, \n",
    "    sample_values_solution = sample_values_solution,\n",
    "    excluded_variables = excluded_variables, \n",
    "    character_classification_threshold = character_classification_threshold\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59351c5b-d5af-47f5-9247-92c3a1ad4a95",
   "metadata": {},
   "source": [
    "# Outlier replacement for numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df4d7d-3ef1-4f98-9735-39fa8c187267",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outlier_variables = [i for i in original_candidate_variables_numeric if i not in excluded_variables]\n",
    "data_full, outlier_info = dtran.replace_outliers(\n",
    "    input_data = data_full, \n",
    "    variables = outlier_variables, \n",
    "    weight_variable = weight_variable_name_solution, \n",
    "    data_path = data_path, \n",
    "    outlier_info_file = 'outlier_info.csv', \n",
    "    iqr_coef = iqr_coef\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3686cbf1-e59a-4e2f-8479-7a25c0543b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split sample data\n",
    "data, temp_dict = dtran.split_sample_data(\n",
    "    input_data=data_full, \n",
    "    sample_values_solution=sample_values_solution, \n",
    "    sample_variable_name_solution=sample_variable_name_solution\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597c12b4-cd50-41b2-bcb7-d5cf21e704f0",
   "metadata": {},
   "source": [
    "# Convert categorical variables to binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2832c10-0c37-4035-92a6-816de37cf979",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = dtran.character_to_binary(\n",
    "    input_data = data_full, \n",
    "    input_variable_list = keep_char_vars_levels, \n",
    "    drop = 'last', # Specifies which value to drop from the one hot encoder. None will return binary variables for all categories. 'first' will drop the most populated category. 'last' will drop the least populated category. \n",
    "    protected_class_valid_values = None # Specifies accepted values for the protected class column. For non-protected class conversions use 'None'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1111d278-52f8-4b58-956f-ea28dee42dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split sample data\n",
    "data, temp_dict = dtran.split_sample_data(\n",
    "    input_data=data_full, \n",
    "    sample_values_solution=sample_values_solution, \n",
    "    sample_variable_name_solution=sample_variable_name_solution\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37801e9-1ec1-4f29-bd73-76c012cb8667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep all numeric variables, including those that were one-hot encoded\n",
    "keep_num_vars = ufun.identify_numeric_variables(input_data=data['data_{}'.format(sample_values_solution[0])])\n",
    "keep_num_vars = [x for x in keep_num_vars if x not in excluded_variables]\n",
    "print('Keeping the following variables: ', keep_num_vars)\n",
    "print(len(keep_num_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a899eb-a3a8-4747-ad54-0c04fdbfdd1e",
   "metadata": {},
   "source": [
    "# Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74747932-1796-4caf-af35-2ecbe662b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_with_missing_dict = vr.select_missing_variables_to_drop_dict(\n",
    "    sample_values_dict = sample_values_dict, \n",
    "    data_path = data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9b0a87-0b2f-4559-bc0d-a339b93f6579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric features with missing values. Imputation will be applied to only these features, in order to improve the performance of the code. \n",
    "variables_with_missing = list(dict.fromkeys(sum(variables_with_missing_dict.values(), [])))\n",
    "num_variables_with_missing = [i for i in keep_num_vars if i in variables_with_missing]\n",
    "num_variables_with_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4b63a1-3b5d-403f-a09f-124f6d04a6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "start_time = time.time()\n",
    "impute_missing = dtran.impute_missing(\n",
    "        variables = num_variables_with_missing, \n",
    "        imputation_strategy = impute_missing_imputation_strategy)\n",
    "impute_missing.imputation_fit_weight(\n",
    "        input_data = data['data_{}'.format(sample_values_solution[0])], \n",
    "        weight_variable = weight_variable_name_solution)\n",
    "\n",
    "for i, j in sample_values_dict.items():\n",
    "    impute_missing.imputation_transform(input_data = data['data_{}'.format(i)])\n",
    "\n",
    "print('This code took %.2fs. to run'%(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122b8acc-8c3c-4b95-abeb-fc8e1df21ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values for imputed variables\n",
    "for i, j in sample_values_dict.items():\n",
    "    start_time = time.time()\n",
    "    print(ufun.color.BOLD + ufun.color.PURPLE + ufun.color.UNDERLINE + 'SAMPLE ' + i + ufun.color.END)\n",
    "\n",
    "    if num_variables_with_missing != []:\n",
    "        print(data['data_{}'.format(i)][num_variables_with_missing].apply\n",
    "              (lambda x: (sum(data['data_{}'.format(i)][x.isnull()][weight_variable_name_solution])\n",
    "                /sum(data['data_{}'.format(i)][weight_variable_name_solution])) * 100, axis=0).sort_values(ascending=False))\n",
    "    else: \n",
    "        print('There are no variables with missing values to impute')\n",
    "\n",
    "    print('This code took %.2fs. to run'%(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be7c26c-5ee9-4765-be57-13988e861dfd",
   "metadata": {},
   "source": [
    "# Drop numeric variables with only one value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a123358d-39c6-44c8-a727-d0f1321fba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_num_vars_one_v = vr.keep_num_variables_one_value(\n",
    "    keep_num_vars = keep_num_vars, \n",
    "    data_path = data_path, \n",
    "    dq_report = 'data_quality_report.csv'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e89279-4747-42db-ac18-7a20c778b566",
   "metadata": {},
   "source": [
    "# Drop variables based on low Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496f152b-e489-4587-9438-75cb339fe606",
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_table = fe.gini_values_weight(feats = keep_num_vars_one_v, \n",
    "                   input_data = data['data_{}'.format(sample_values_solution[0])], \n",
    "                   target_variable = target_variable_name, \n",
    "                   weight_variable = weight_variable_name_solution, \n",
    "                   data_path = data_path, \n",
    "                   gini_info_file = 'gini_info.csv', \n",
    "                   n_bands = 10)\n",
    "keep_num_vars_gini = list(gini_table.loc[gini_table['Gini coefficient'] >= gini_threshold, 'variable'].values)\n",
    "print(ufun.color.PURPLE + 'Keeping the following variables with Gini > ' + str(gini_threshold) + ': ' + ufun.color.END + str(keep_num_vars_gini))\n",
    "print(len(keep_num_vars_gini))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ab2282-4cbe-402e-b073-41f0b10f17ad",
   "metadata": {},
   "source": [
    "# Remove highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d08c088-6458-44b8-b8cc-b0940ad20b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = fe.calculate_correlations(\n",
    "    input_data = data['data_{}'.format(sample_values_solution[0])], \n",
    "    features = keep_num_vars_gini, \n",
    "    corr_threshold = corr_threshold, \n",
    "    weight_variable_name = weight_variable_name_solution\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116503e1-03e3-4fae-8631-7d3086e4beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "eliminated, remaining_predictors = fe.correlation_elimination(\n",
    "    method = 'correlation', \n",
    "    features = keep_num_vars_gini, \n",
    "    input_data = data['data_{}'.format(sample_values_solution[0])], \n",
    "    data_path = data_path, \n",
    "    corr_threshold = corr_threshold, \n",
    "    top_n = top_n, \n",
    "    weight_variable_name = weight_variable_name_solution, \n",
    "    correlations = corrs\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd06a43b-7295-401d-9a19-f535b8f0eaf8",
   "metadata": {},
   "source": [
    "# Optional: VIF elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c004ecf6-1d54-49bc-bd10-60052c4a0c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "eliminated, remaining_predictors = fe.run_VIF(\n",
    "    VIF_reduction = VIF_reduction, \n",
    "    features = remaining_predictors, \n",
    "    input_data = data['data_{}'.format(sample_values_solution[0])], \n",
    "    data_path = data_path, \n",
    "    vif_threshold = first_vif_threshold, \n",
    "    corr_threshold = corr_threshold, \n",
    "    weight_variable_name = weight_variable_name_solution\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8e2ebe-4315-4069-87e1-67f38be0d4ba",
   "metadata": {},
   "source": [
    "# Lasso Logistic Regression for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e14a271-12cf-4bd4-997d-faa17f314fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_dict = fe.perform_lasso(\n",
    "    sample_values_dict = sample_values_dict, \n",
    "    sample_values_solution = sample_values_solution, \n",
    "    data = data, \n",
    "    target_variable_name = target_variable_name, \n",
    "    predictor_variables = remaining_predictors, \n",
    "    data_path = data_path, \n",
    "    LogisticRegression_solver = LogisticRegression_solver,\n",
    "    early_stop = True, \n",
    "    weight_variable_name = weight_variable_name_solution, \n",
    "    standardization=False, \n",
    "    c_min = 1e-4, \n",
    "    c_max = 0.5, \n",
    "    num = 10, \n",
    "    vif_threshold = second_vif_threshold, \n",
    "    random_state = 42, \n",
    "    lasso_criterion = lasso_criterion\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4aa689-8b33-4448-9985-7022544f8fef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso = bic_dict[next(iter(bic_dict))]\n",
    "# Obtain the best C value based on the criterion selected by the user\n",
    "lasso.best_vars()\n",
    "# Running the second VIF using the lasso_features from the best_vars function\n",
    "vifs = lasso.calculate_vifs(lasso.lasso_features, weight_variable_name=weight_variable_name_solution, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d879800-58e8-4e9a-a80d-d23d5a4659d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Obtain the final list of features after the second VIF threshold calculation\n",
    "final_vars = lasso.remaining_predictors()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59f3f9c-ca66-4f7e-ae57-fe5fca5ef918",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb007a3-a6d9-4209-ad15-f7d8bedaad61",
   "metadata": {},
   "source": [
    "## Remove features based on p-value information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac8cc3d-e58d-4d98-9083-4f301fd3be7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_pre = ml.logistic_regression(\n",
    "    input_data = data, \n",
    "    final_feats = final_vars, \n",
    "    target_variable = target_variable_name, \n",
    "    weight_variable_name = weight_variable_name_solution, \n",
    "    data_path = data_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f377e15b-221a-4f95-8531-336d22a7cc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_features = logistic_regression_pre.stepwise_fun(sample_values_solution = sample_values_solution, \n",
    "        method = 'backward', # Possible values: 'backward', 'forward', 'combined'\n",
    "        number_of_features = None, # Set to None to allow for feature selection using the p-value\n",
    "        significance_level = 0.05 # Features with p-value greater than this threshold will not be included in the selected features    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d946fc-4190-41e9-8d41-9817fac8d554",
   "metadata": {},
   "source": [
    "## Execute Logistic regression based on the remaining features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8a773c-4af8-43d0-8a90-5be9e219c59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = ml.logistic_regression(\n",
    "    input_data = data, \n",
    "    final_feats = stepwise_features, \n",
    "    target_variable = target_variable_name, \n",
    "    weight_variable_name = weight_variable_name_solution, \n",
    "    data_path = data_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cd2256-bedd-4d23-b3c4-a7052a089c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg_glm, lreg_summary = logistic_regression.glm_bin(\n",
    "    sample_values_solution = sample_values_solution \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc0877-ff92-4a3c-a138-698f18ce953b",
   "metadata": {},
   "source": [
    "## Produce reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec39675-8037-4fd7-96be-b5e9b6d54168",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_output = logistic_regression.glm_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff864d8-4f52-4fcb-8742-c5d9cf53d38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframes dictionary with the predicted variables that will be used as input to other reports\n",
    "predictions_dict = logistic_regression.create_predictions(\n",
    "        sample_values_dict=sample_values_dict, \n",
    "        amount_variable_name = amount_variable_name_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390b7c8c-acdd-4398-92d8-afc721414927",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_regression_report_class = rp.binary_regression_report(\n",
    "    predictions_dictionary = predictions_dict, \n",
    "    target_variable = target_variable_name, \n",
    "    predicted_score_numeric = 'predicted_score_numeric', \n",
    "    amount_variable_name = amount_variable_name_solution, \n",
    "    weight_variable_name = weight_variable_name_solution, \n",
    "    sample_values_dict = sample_values_dict, \n",
    "    select_top_percent = 100, \n",
    "    n_bands = 10, \n",
    "    rows = 10, \n",
    "    data_path = data_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f871e9-6ebb-4e6c-aced-071dda9f067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_eval = binary_regression_report_class.get_evaluation(predicted_score_binary = 'predicted_score_binary', \n",
    "                                                       filename = 'evaluation_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f91c96-caab-4dfd-8b17-c04e4be39d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lift table\n",
    "lift_table_dict = binary_regression_report_class.create_lift_table(filename = 'lift_table_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851a3f21-cada-4fc8-8c75-cb5ccbeb6c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder, if it doesn't exist\n",
    "folder_name = 'graphs_LR'\n",
    "ufun.create_folder(data_path = data_path, \n",
    "                   folder_name = 'output/{}'.format(folder_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ec435e-48ad-4ad6-8b63-53e9c7cd392a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "binary_regression_report_class.plot_ADR_Quantile(\n",
    "        folder_name = folder_name,\n",
    "        xlim=None, \n",
    "        ylim=None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc9d41e-158d-4a51-93bd-061fee26341a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "binary_regression_report_class.plot_cADR_Quantile(\n",
    "        folder_name = folder_name,\n",
    "        xlim=None, \n",
    "        ylim=None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c806bb-d2ac-449d-8fcf-a514da09817a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "binary_regression_report_class.plot_FPR_Quantile(\n",
    "        folder_name = folder_name,\n",
    "        xlim=None, \n",
    "        ylim=None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ba0470-eb2f-4517-b3b1-204f3ae4c7b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "binary_regression_report_class.plot_cFPR_Quantile(\n",
    "        folder_name = folder_name,\n",
    "        xlim=None, \n",
    "        ylim=None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c3bbdf-937a-4bb3-8041-04a6230e5f7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "binary_regression_report_class.plot_ROC_curve(folder_name = folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dde555-a50a-4167-84cd-473345c22c7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "binary_regression_report_class.plot_precision_recall_curve(folder_name = folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fd3568-22e7-4db5-813f-19054d29f3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_regression_report_class.plot_cutoffs(\n",
    "        folder_name = folder_name,\n",
    "        n_bands = 100, # Number of bands between 0 and 1\n",
    "        cost_fp = 500, # Cost of blocking a legitimate customer\n",
    "        cost_fn = 10000, # Cost of missing a fraud/credit risk customer\n",
    "        return_table=True # Set to True in order to return the table that produced the graph, otherwise set to False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f679aa-373e-4df6-bafd-1d97c0b4c35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(rp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Supervised Modeling Solution",
   "language": "python",
   "name": "supervised_modeling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
