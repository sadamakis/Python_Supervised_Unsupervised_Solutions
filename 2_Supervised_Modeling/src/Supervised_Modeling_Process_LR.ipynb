{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811a4d67-7a58-4876-809d-0d458d5af588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the notebook full screen\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e4a306-c188-4322-b9dc-a1945462d1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import sys \n",
    "\n",
    "if sys.version_info[:3] < (3,4):\n",
    "    os.getcdw()\n",
    "    code_dir = os.path.dirname(os.getcdw())\n",
    "    project_dir = os.path.dirname(os.path.dirname(os.getcdw()))\n",
    "    data_path = os.path.join(code_dir, \"data\")\n",
    "    functions_path = os.path.join(project_dir, \"functions\")\n",
    "else: \n",
    "    from pathlib import Path\n",
    "    current_directory = os.path.dirname(Path.cwd())\n",
    "    code_dir = os.path.dirname(current_directory)\n",
    "    project_dir = os.path.join(code_dir, \"2_Supervised_Modeling\")\n",
    "    data_path = os.path.join(code_dir, \"2_Supervised_Modeling\\\\data\")\n",
    "    functions_path = os.path.join(code_dir, 'functions')\n",
    "    \n",
    "#code_dir = r'D:\\BackUp - 151110\\Side_Projects\\Analytical_Solutions\\Sotiris_Solutions\\2_Supervised_Modeling\\src'\n",
    "#project_dir = r'D:\\BackUp - 151110\\Side_Projects\\Analytical_Solutions\\Sotiris_Solutions\\2_Supervised_Modeling'\n",
    "#data_path = r'D:\\BackUp - 151110\\Side_Projects\\Analytical_Solutions\\Sotiris_Solutions\\2_Supervised_Modeling\\data'\n",
    "#functions_path = r'D:\\BackUp - 151110\\Side_Projects\\Analytical_Solutions\\Sotiris_Solutions\\functions'\n",
    "#print(code_dir)\n",
    "print(project_dir)\n",
    "print(data_path)\n",
    "print(functions_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481f4f52-0696-4ae1-bc95-872a27ff04d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Python modules\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c4c50-c0a9-4bb8-bbdd-3a3577db63e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path for the library\n",
    "import sys\n",
    "sys.path.insert(0, functions_path)\n",
    "import variable_reduction as vr\n",
    "from solution_steps import color\n",
    "from data_quality_report import dq_report\n",
    "import preprocessing as pp\n",
    "import data_processing as cpd\n",
    "import lasso_feature_selection as lfs\n",
    "import logistic_regression as lreg \n",
    "from load_data import load_data\n",
    "import solution_steps as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba69179b-c611-4e48-81b9-288704db5818",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eb9ff6-092c-4045-b77b-cbfdd806f4a9",
   "metadata": {},
   "source": [
    "# Initialize the solution variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79160fd2-bbd1-4867-8e81-a5ce75059076",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(project_dir, 'data/input/Supervised_Modeling_Solution_Input.json')) as f:\n",
    "    inputs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97136bd-4dae-4125-8fec-d25b1520dcb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba251a6-b67b-420e-a894-857de08b1b4b",
   "metadata": {},
   "source": [
    "## Essential parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b5b784-ed72-4cb5-8665-88243a6cb2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# String. Specify how to load the data. Options: csv, parq.\n",
    "Load_from = inputs[\"Load_from\"]\n",
    "# String. Specify the data location: this is the folder where the data for this project are saved. \n",
    "data_location = inputs[\"data_location\"]\n",
    "# String. Set the input data file. \n",
    "table_name = inputs[\"table_name\"]\n",
    "# Float. Number between 0-1 determining what percent of data to subsample. \n",
    "sample = float(inputs[\"sample\"])\n",
    "# String. Set the target variable name in the original dataset. \n",
    "target_variable_name = inputs[\"target_variable_name\"]\n",
    "# String. Set the weight variable name in the original dataset. If not avaulable, then provide \"None\".\n",
    "weight_variable_name = inputs[\"weight_variable_name\"]\n",
    "# String. Set the sample column that has sample information, e.g. train/test/OOT or segment information, and will be used to split the data in different samples\n",
    "# If this column does not exist, then provide \"None\".\n",
    "sample_variable_name = inputs[\"sample_variable_name\"]\n",
    "# List of strings. Set the sub-sample values that are in the sample_variable_name field, e.f. for train/test data split and/or for different segments. \n",
    "# All samples defined in this parameters will be picked up by the solution and results will be created for these samples. \n",
    "# If sample column does not exist, then provide '[None]' (without quotes).\n",
    "sample_values = inputs[\"sample_values\"]\n",
    "# List. Provide the feature names for the numeric variables that will be used for modeling. \n",
    "original_candidate_variables_numeric = inputs[\"numeric_variables_modeling\"]\n",
    "# List. Provide the feature names for the character variables that will be used for modeling. \n",
    "original_candidate_variables_character = inputs[\"character_variables_modeling\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba96f056-7353-42c3-bb1f-1be4c34714a0",
   "metadata": {},
   "source": [
    "## Advanced parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4a8d27-1b3f-438e-8485-69d867daf5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Float. Takes values between 0 and 1. Used in 'select_missing_variables_to_drop' function. Variables with percentage missing values above this threshold will be \n",
    "# dropped from the rest of the process. \n",
    "select_missing_variables_to_drop_threshold = inputs[\"select_missing_variables_to_drop_threshold\"]\n",
    "# Integer. Used in 'character_classification' function. Character variables with more levels than this threshold will be dropped from the rest of the process. \n",
    "character_classification_threshold = inputs[\"character_classification_threshold\"]\n",
    "# Float. Used in the 'replace_outliers' function in the outlier removal section. This is the coefficient for Interquantile range. \n",
    "# It can be used to adjust how many outliers to replace; the higher the value the less outliers are replaced. \n",
    "iqr_coef = inputs[\"iqr_coef\"]\n",
    "# String. Used in 'impute_missing' class. Select the stratefy to impute the missing values. Current options are \"median\", \"mean\", \n",
    "# or a specific value without quotes, e.g. 0.\n",
    "impute_missing_imputation_strategy = inputs[\"impute_missing_imputation_strategy\"]\n",
    "# Float. Variables with Gini coefficient below this threshold will be dropped from the reamained of the analysis. \n",
    "gini_threshold = inputs[\"gini_threshold\"]\n",
    "# Float. Used in 'corr_eliminator' function in the initial correlations calculations. Variables with correlation greater than this threshold will be dropped. \n",
    "corr_threshold = inputs[\"corr_threshold\"]\n",
    "# Int. Used in the 'corr_eliminator' function in the initial correlations calculations. After highly correlated features are dropped, this is the number of the next highest correlations. \n",
    "top_n = eval(inputs[\"top_n\"])\n",
    "# Float. Used in the 'vif_eliminator' function in the initial VIF calculations. Variables with VIF greater than this threshold will be dropped.\n",
    "first_vif_threshold = inputs[\"first_vif_threshold\"]\n",
    "# Float. Used in the 'vif_eliminator' function in the Lasso Logistic Regression. Variables with VIF greater than this threshold will be dropped.\n",
    "second_vif_threshold = inputs[\"second_vif_threshold\"]\n",
    "# String. User selects which criterion to optimize for feature selection. Options are: \"AIC\", \"BIC\".\n",
    "lasso_criterion = inputs[\"lasso_criterion\"]\n",
    "# Boolean. Used to determine whether VIF is run after the correlation feature elimination step. \n",
    "VIF_reduction = inputs[\"VIF_reduction\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e438bde-3333-478d-93e1-5df10740b2b8",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24b4d66-7b86-4f49-a97a-9dfcd556b0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = load_data(method = Load_from, \n",
    "                     data_path = data_location, \n",
    "                     table_name = table_name, \n",
    "                     sample = sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a47f3de-ccf2-45ee-8453-5d06735fc594",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3680f4f7-c64b-429c-bb80-12a0c862b584",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929d4911-7cc7-428f-8d88-45aaa2ed195f",
   "metadata": {},
   "source": [
    "# Create the Weight and Sample variables, if not available in the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee51b3c-dd87-4976-b7e3-b87a8f102f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the weight variable\n",
    "data_full, weight_variable_name_solution = ss.weight_var_assignment(data_full = data_full, \n",
    "                                                                 weight_variable_name = weight_variable_name)\n",
    "\n",
    "# Create the sample variable\n",
    "data_full, sample_values_solution, sample_variable_name_solution = ss.sample_var_assignment(data_full = data_full, \n",
    "                                                                                         sample_variable_name = sample_variable_name, \n",
    "                                                                                           sample_values = sample_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05fa0d3-f687-4ff8-81b1-4bdcd384cb5f",
   "metadata": {},
   "source": [
    "# Convert variable data types based on user information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3d5749-f47c-448d-b01a-271a922f7e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert character variables\n",
    "data_full, character_variables_list = ss.convert_character_var(data_full = data_full, \n",
    "                                                        original_candidate_variables_character = original_candidate_variables_character,\n",
    "                                                        sample_variable_name_solution = sample_variable_name_solution)\n",
    "\n",
    "# Convert numeric variables\n",
    "data_full, numeric_variables_list = ss.convert_numeric_var(data_full = data_full, \n",
    "                                                        original_candidate_variables_numeric = original_candidate_variables_numeric,\n",
    "                                                        weight_variable_name_solution = weight_variable_name_solution, \n",
    "                                                        target_variable_name = target_variable_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec215d6e-1a0a-4cbb-9b28-85ba476a96f6",
   "metadata": {},
   "source": [
    "# Data quality report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee1bd6e-5c3a-4e03-a55d-200083ab4b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "dq = dq_report(df = data_full, \n",
    "                data_path = data_path, \n",
    "                variables = character_variables_list + numeric_variables_list, \n",
    "                weight_variable = weight_variable_name_solution, \n",
    "                dq_report_file = 'data_quality_report.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c670fb-a527-4ca5-aca8-59694138182f",
   "metadata": {},
   "source": [
    "# Split sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15870ef1-fbea-4446-af80-8aa295e65658",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sample_values_dict = ss.split_sample_data(\n",
    "    data_full=data_full, \n",
    "    sample_values_solution=sample_values_solution, \n",
    "    sample_variable_name_solution=sample_variable_name_solution\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0229ddf9-035c-4e08-93aa-9c4fd57ce689",
   "metadata": {},
   "source": [
    "# Set the original candidate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecc5066-89ef-4e75-8dd0-dc0eab583f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_candidate_variables = original_candidate_variables_character + original_candidate_variables_numeric\n",
    "print(color.BLUE + 'Original candidate variables: ' + color.END + str(original_candidate_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f35b0e-1824-4b26-a14b-34473e054d44",
   "metadata": {},
   "source": [
    "# Remove variables with high missing values percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e79733-2d94-49d9-bc96-ec499df6bdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables excluded from the non-predictive features: keys, target, sample, etc\n",
    "excluded_variables = [x for x in data['data_{}'.format(sample_values_solution[0])].columns if x not in original_candidate_variables]\n",
    "print(color.BLUE + 'Variables to be excluded: ' + color.END + str(excluded_variables))\n",
    "print()\n",
    "# Produce and save the missing values table to review\n",
    "missing_variables_table, missing_variables = ss.missing_values_vars(\n",
    "    sample_values_dict=sample_values_dict, \n",
    "    data_path=data_path, \n",
    "    data=data, \n",
    "    weight_variable_name_solution=weight_variable_name_solution, \n",
    "    select_missing_variables_to_drop_threshold=select_missing_variables_to_drop_threshold\n",
    "    )\n",
    "# Create the variables to remove: non-predictors + variables with too many missing information\n",
    "excluded_variables = excluded_variables + missing_variables\n",
    "print(color.BLUE + 'Variables to remove from the remainder of the analysis: ' + color.END + str(excluded_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0c0e14-df5c-4af2-b574-e65b13c658b5",
   "metadata": {},
   "source": [
    "# Remove character variables with many levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64546dd3-f228-401b-976c-ac6cd142e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_char_vars_levels = ss.character_var_levels(\n",
    "    data = data, \n",
    "    data_path = data_path, \n",
    "    sample_values_solution = sample_values_solution,\n",
    "    excluded_variables = excluded_variables, \n",
    "    character_classification_threshold = character_classification_threshold\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59351c5b-d5af-47f5-9247-92c3a1ad4a95",
   "metadata": {},
   "source": [
    "# Outlier replacement for numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df4d7d-3ef1-4f98-9735-39fa8c187267",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outlier_variables = [i for i in original_candidate_variables_numeric if i not in excluded_variables]\n",
    "data_full = cpd.replace_outliers(\n",
    "    input_data = data_full, \n",
    "    variables = outlier_variables, \n",
    "    weight_variable = weight_variable_name_solution, \n",
    "    data_path = data_path, \n",
    "    outlier_info_file = 'outlier_info.csv', \n",
    "    iqr_coef = iqr_coef\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf04806-73b8-4aa9-bd85-4b8642fb173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split sample data\n",
    "data = {}\n",
    "for i, j in sample_values_dict.items():\n",
    "    start_time = time.time()\n",
    "    print(color.BOLD + color.PURPLE + color.UNDERLINE + j + color.END)\n",
    "    \n",
    "    data['data_{}'.format(i)] = data_full[data_full[sample_variable_name_solution]==i]\n",
    "    print('The shape is: ', data['data_{}'.format(i)].shape)\n",
    "    \n",
    "    print('This code took %.2fs. to run'%(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597c12b4-cd50-41b2-bcb7-d5cf21e704f0",
   "metadata": {},
   "source": [
    "# Convert categorical variables to binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8979d9e-35ec-4711-89ca-0e5667ef5675",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd.character_to_binary(\n",
    "    input_data = data_full, \n",
    "    input_variable_list = keep_char_vars_levels, \n",
    "    drop = 'last', # Specifies which value to drop from the one hot encoder. None will return binary variables for all categories. 'first' will drop the most populated category. 'last' will drop the less populated category. \n",
    "    protected_class_valid_values = None # Specifies accepted values for the protected class column. For non-protected class conversions use 'None'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbba151-f45b-4056-a21e-75ed156dd986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split sample data\n",
    "data = {}\n",
    "for i, j in sample_values_dict.items():\n",
    "    start_time = time.time()\n",
    "    print(color.BOLD + color.PURPLE + color.UNDERLINE + j + color.END)\n",
    "    \n",
    "    data['data_{}'.format(i)] = data_full[data_full[sample_variable_name_solution]==i]\n",
    "    print('The shape is: ', data['data_{}'.format(i)].shape)\n",
    "    \n",
    "    print('This code took %.2fs. to run'%(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bd46ba-2885-4baa-80da-b58efe6a85ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep all numeric variables, including those that were one-hot encoded\n",
    "keep_num_vars = cpd.identify_numeric_variables(input_data=data['data_{}'.format(sample_values_solution[0])])\n",
    "keep_num_vars = [x for x in keep_num_vars if x not in excluded_variables]\n",
    "print('Keeping the following variables: ', keep_num_vars)\n",
    "print(len(keep_num_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a899eb-a3a8-4747-ad54-0c04fdbfdd1e",
   "metadata": {},
   "source": [
    "# Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485a4c89-ac57-45b7-8533-ef232b067eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_with_missing_dict = {}\n",
    "for i, j in sample_values_dict.items():\n",
    "    start_time = time.time()\n",
    "    print(color.BOLD + color.PURPLE + color.UNDERLINE + j + color.END)\n",
    "    \n",
    "    variables_with_missing_dict['variables_with_missing_dict_{}'.format(i)] = cpd.select_missing_variables_to_drop(\n",
    "    data_path = data_path, \n",
    "    sample_name = j, \n",
    "    threshold = 0\n",
    "    )\n",
    "    \n",
    "    print('This code took %.2fs. to run'%(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd80a1e0-5945-41fd-8300-fa03fd8f3e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric features with missing values. Imputation will be applied to only these features, in order to improve the performance of the code. \n",
    "variables_with_missing = list(dict.fromkeys(sum(variables_with_missing_dict.values(), [])))\n",
    "num_variables_with_missing = [i for i in keep_num_vars if i in variables_with_missing]\n",
    "num_variables_with_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85479abb-c97f-42e2-82f4-6bb99a68c8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "start_time = time.time()\n",
    "impute_missing = cpd.impute_missing(\n",
    "        variables = num_variables_with_missing, \n",
    "        imputation_strategy = impute_missing_imputation_strategy)\n",
    "impute_missing.imputation_fit_weight(\n",
    "        input_data = data['data_{}'.format(sample_values_solution[0])], \n",
    "        weight_variable = weight_variable_name_solution)\n",
    "\n",
    "for i, j in sample_values_dict.items():\n",
    "    impute_missing.imputation_transform(input_data = data['data_{}'.format(i)])\n",
    "\n",
    "print('This code took %.2fs. to run'%(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79673b4-8cc8-430e-92ab-b6eb2e7273af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check missing values for imputed variables\n",
    "for i, j in sample_values_dict.items():\n",
    "    start_time = time.time()\n",
    "    print(color.BOLD + color.PURPLE + color.UNDERLINE + j + color.END)\n",
    "\n",
    "    if num_variables_with_missing != []:\n",
    "        print(data['data_{}'.format(i)][num_variables_with_missing].apply\n",
    "              (lambda x: (sum(data['data_{}'.format(i)][x.isnull()][weight_variable_name_solution])\n",
    "                /sum(data['data_{}'.format(i)][weight_variable_name_solution])) * 100, axis=0).sort_values(ascending=False))\n",
    "    else: \n",
    "        print('There are no variables with missing values to impute')\n",
    "\n",
    "    print('This code took %.2fs. to run'%(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be7c26c-5ee9-4765-be57-13988e861dfd",
   "metadata": {},
   "source": [
    "# Drop numeric variables with only one value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a123358d-39c6-44c8-a727-d0f1321fba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_num_vars_one_v = ss.keep_num_variables_one_value(\n",
    "    keep_num_vars = keep_num_vars, \n",
    "    data_path = data_path, \n",
    "    dq_report = 'data_quality_report.csv'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e89279-4747-42db-ac18-7a20c778b566",
   "metadata": {},
   "source": [
    "# Drop variables based on low Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3187162d-65be-451c-89c4-db49772a15e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_table = pp.gini_values_weight(feats = keep_num_vars_one_v, \n",
    "                   input_data = data['data_{}'.format(sample_values_solution[0])], \n",
    "                   target_variable = target_variable_name, \n",
    "                   weight_variable = weight_variable_name_solution, \n",
    "                   data_path = data_path, \n",
    "                   gini_info_file = 'gini_info.csv', \n",
    "                   n_bands = 10)\n",
    "keep_num_vars_gini = list(gini_table.loc[gini_table['Gini coefficient'] >= gini_threshold, 'variable'].values)\n",
    "print(color.PURPLE + 'Keeping the following variables with Gini > ' + str(gini_threshold) + ': ' + color.END + str(keep_num_vars_gini))\n",
    "print(len(keep_num_vars_gini))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ab2282-4cbe-402e-b073-41f0b10f17ad",
   "metadata": {},
   "source": [
    "# Remove highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39667c34-9fe1-4fa4-9c4a-1df95acee00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = vr.calculate_correlations(\n",
    "    train_df = data['data_{}'.format(sample_values_solution[0])], \n",
    "    features = keep_num_vars_gini, \n",
    "    corr_threshold = corr_threshold, \n",
    "    weight_variable_name = weight_variable_name_solution\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eed3b6-70e1-4b9c-b5b0-5caea4989faa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eliminated, remaining_predictors = vr.correlation_elimination(\n",
    "    method = 'correlation', \n",
    "    features = keep_num_vars_gini, \n",
    "    train_df = data['data_{}'.format(sample_values_solution[0])], \n",
    "    data_path = data_path, \n",
    "    corr_threshold = corr_threshold, \n",
    "    top_n = top_n, \n",
    "    weight_variable_name = weight_variable_name_solution, \n",
    "    correlations = corrs\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd06a43b-7295-401d-9a19-f535b8f0eaf8",
   "metadata": {},
   "source": [
    "# Optional: VIF elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582a0b70-4698-4704-a5aa-edc79e55b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "eliminated, remaining_predictors = vr.run_VIF(\n",
    "    VIF_reduction = VIF_reduction, \n",
    "    features = remaining_predictors, \n",
    "    train_df = data['data_{}'.format(sample_values_solution[0])], \n",
    "    data_path = data_path, \n",
    "    vif_threshold = first_vif_threshold, \n",
    "    corr_threshold = corr_threshold, \n",
    "    weight_variable_name = weight_variable_name_solution\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8e2ebe-4315-4069-87e1-67f38be0d4ba",
   "metadata": {},
   "source": [
    "# Lasso Logistic Regression for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7642a30-0c45-4792-b6e1-227e1499953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_dict = ss.perform_lasso(\n",
    "    sample_values_dict = sample_values_dict, \n",
    "    sample_values_solution = sample_values_solution, \n",
    "    data = data, \n",
    "    target_variable_name = target_variable_name, \n",
    "    predictor_variables = remaining_predictors, \n",
    "    data_path = data_path, \n",
    "    early_stop = True, \n",
    "    weight_variable_name = weight_variable_name_solution, \n",
    "    standardization=False, \n",
    "    c_min = 1e-4, \n",
    "    c_max = 0.5, \n",
    "    num = 10, \n",
    "    vif_threshold = second_vif_threshold, \n",
    "    random_state = 42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884acbca-e75a-4f74-bfd5-55b13300a447",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = bic_dict['training']\n",
    "# Obtain the best C value based on the criterion selected by the user\n",
    "lasso.best_vars(lasso_criterion)\n",
    "# Running the second VIF using the lasso_features from the best_vars function\n",
    "vifs = lasso.calculate_vifs(lasso.lasso_features, weight_variable_name=weight_variable_name_solution, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80eed2c-72df-48a1-b0bd-2279927a03f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the final list of features after the second VIF threshold calculation\n",
    "final_vars = lasso.remaining_predictors()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59f3f9c-ca66-4f7e-ae57-fe5fca5ef918",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8afb82-038e-491c-8de8-92688e45e578",
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg_glm, lreg_summary = lreg.glm_bin(\n",
    "    sample_values_solution = sample_values_solution, \n",
    "    data = data, \n",
    "    final_feats = final_vars, \n",
    "    target_variable_name = target_variable_name, \n",
    "    weight_variable_name_solution = weight_variable_name_solution\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf90d4-730f-492b-beaf-70ec8c2b8f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = lreg.glm_report(\n",
    "    data_path = data_path, \n",
    "    glm_bin_summary = lreg_summary\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e5f374-e589-4428-803a-c8b7a1dc254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ = lreg.get_evaluation(\n",
    "    model = lreg_glm, \n",
    "    sample_values_dict = sample_values_dict, \n",
    "    final_feats = final_vars, \n",
    "    target_variable_name = target_variable_name, \n",
    "    data = data, \n",
    "    data_path = data_path\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Supervised Modeling Solution",
   "language": "python",
   "name": "supervised_modeling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
